# 简述
该部分笔记主要记录《机器学习》视频中的：**神经网络(Neural Networks)算法**
包含视频内容范围为第八周和第九周视频，主要内容分为以下部分：
- 神经网络
- 神经网络的应用
- 神经网络算法

假设我们现在存在一个房价预测问题，不过这一次不再是预测房价（回归问题），而是预测未来6个月是否能售出（分类问题）。如果有100个独立特征，例如：
![](https://i.imgur.com/9lsvs9N.png)

当我们任取两个特征作为组合特征时，大约可以得到5000个特征；当我们任取3个特征作为组合特征时，大约可以得到170000个特征。在这种情况下，逻辑回归算法处理起来，时间复杂度相对比较高，分别为\\( O(n^2) \\)和\\( O(n^3) \\)。
在图像处理领域，假设我们需要处理的一幅图片有50 x 50 = 2500个像素，那么每个样本有2500个像素点可以选择，如果是是二次项组合特征，大约有3百万个特征组合。
对于这样的有着大量特征的分类问题，除了逻辑回归，是否还有其他的学习算法？答案是肯定的，接下来介绍的神经网络(Neural Networks)算法，对于复杂的假设空间和复杂的非线性问题有很好的学习能力。
# 神经网络
历史上，科学家一直希望模拟人的大脑，造出可以思考的机器。人为什么能够思考？科学家发现，原因在于人体的神经网络。
- 起源于尝试让机器模仿大脑的算法；
- 在80年代和90年代早期非常流行，慢慢在90年代后期衰落；
- 最近得益于计算机硬件能力，又开始流行起来：对于很多应用，神经网络算法是一种“时髦”的技术；

## 神经元
![](https://i.imgur.com/OeO47dd.png)
注：下面解释来源于[阮一峰-神经网络入门](http://www.ruanyifeng.com/blog/2017/07/neural-network.html)
1. 外部刺激通过神经末梢，转化为电信号，转导到神经细胞（又叫神经元）。
2. 无数神经元构成神经中枢。
3. 神经中枢综合各种信号，做出判断。
4. 人体根据神经中枢的指令，对外部刺激做出反应。

## 神经元模型
现在我们模拟大脑中的神经元结构建立一个简单的模型-Logistic unit，其中，蓝色圆圈代表输入，橘黄色圆圈代表神经元结点
![](https://i.imgur.com/ymEMSjT.png)

其中\\( x\_1, x\_2, x\_3 \\)称为输入（来自与其他神经元的输入信号）， \\( x\_0 \\)称为偏置单元(bias unit)，值为常数1， \\( \theta \\)称为权重或参数， \\( h\_\theta(x) \\)称为激活函数(activation function)。
![](https://i.imgur.com/RHg2CNf.png)

将多个神经元组织在一起，我们就有了神经网络，例如如下的三层结构的神经网络：
![](https://i.imgur.com/miDd6pA.png)

其中：
- Layer1代表输入层，Layer2代表隐含层，Layer3代表输出层
- 一般来说，神经网络的层数是指隐含层有多少层

对于上图，我们可以有以下数学公式表示：
![](https://i.imgur.com/AEJAAJt.png)

如果神经网络在第\\( j \\)层有\\( s\_j \\)个单元，在第\\( j+1 \\)层有\\( s\_j+1 \\)个单元，那么权重矩阵\\( \Theta^{(j)} \\)的纬度是\\( s\_{j+1} \times (s\_j + 1) \\)

# 神经网络应用
一个非线性二分类器例子
![](https://i.imgur.com/SzHPrgp.png)

简化后：
![](https://i.imgur.com/qYrrnpI.png)

对于这个问题，我们可以利用同或逻辑处理：
## 布尔逻辑知识
- 与：当且仅当两个逻辑变量A和B相同时，逻辑函数F等于1，否则F等于0，这种逻辑关系称为“与”。
- 或：当两个逻辑变量A或B中有一个为真时，逻辑函数F等于1，否则F等于0，这种逻辑关系称为“或”。
- 非：当一个逻辑变量A为真时，逻辑函数F等于0，否则F等于1，这种逻辑关系称为“非”。
- 同或：如果当两个逻辑变量A和B相同时，逻辑函数F等于1，否则F等于0，这种逻辑关系称为“同或”。
- 异或：如果当两个逻辑变量A和B相异时，逻辑函数F等于1，否则F等于0，这种逻辑关系称为“异或”。

## AND(与)逻辑
![](https://i.imgur.com/gIHfVLa.png)

用一个简单的神经网络（一个神经元）表示与逻辑运算：
![](https://i.imgur.com/IYI5cY1.png)

其中激活函数\\( h\_\theta(x) \\)可以用如下公式和图形表示：
![](https://i.imgur.com/Nji2BNS.png)
![](https://i.imgur.com/NthZiHh.png)

对于g(z)来说，当z>=4.0时，g(z)约等于1；当z<=-4.0时，g(z)约等于-1. 对于上述激活函数，将二值(0, 1)变量x1,x2代入，我们得到如下的对应表：
![](https://i.imgur.com/jQtOqr4.png)

## OR(或)逻辑
![](https://i.imgur.com/YxJhL8l.png)

## NOT(非)逻辑
![](https://i.imgur.com/5LzwDFl.png)

## 异或(XOR)
有了上述三个基本逻辑运算的基础和相关的神经网络模型表示，我们可以将其组合为一个略微复杂的”同或(XNOR)逻辑运算的神经网络“：
![](https://i.imgur.com/nVnMXiE.png)

注：
1. 同或运算的表达式如下：\\( F = A \odot B = AB + \overline{A}\overline{B} \\)
2. 上图中第二层隐藏网络a1和a2分别代表了A And B和Not A And Not B，a1和a2又做了一次或逻辑运算就得到了同或逻辑运算。
